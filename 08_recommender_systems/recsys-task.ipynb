{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДПО ВШЭ\n",
    "\n",
    "## Современный анализ данных, глубокое обучение и приложения\n",
    "\n",
    "## Задание на тему: \"Рекомендательные системы\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании будем практиковаться в реализации рекомендательных систем.\n",
    "\n",
    "Воспользуемся небольшим датасетом с Kaggle: [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "719f3966-e6fd-49c8-9f60-7bd741542450",
    "_uuid": "b61cd3125a7f8f991fc1bda85ae3cd26f74090ae"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f5c826d-f3d5-42d3-a7e6-0343a44cdc9f",
    "_uuid": "26f1f70fd978957b26f8884fc5f82bfe9475c666"
   },
   "source": [
    "## Часть 0. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c48b62c-ad3b-4218-8fb2-2f0e86a16edc",
    "_uuid": "650c279eddc846a48274346e045cfb6e1f8895d5"
   },
   "source": [
    "Загрузим [Deskdrop dataset](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop), включающийся в себе логи за 1 год платформы, где пользователи читают статьи.\n",
    "\n",
    "Данные включают в себя 2 файла:  \n",
    "- **shared_articles.csv**\n",
    "- **users_interactions.csv**\n",
    "\n",
    "Как можно догадаться, в одном описания самих статей (нам понадобятся в контентных моделях), а в другом логи пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9ee29ff-1fee-4dc9-a3cb-e5301c17fded",
    "_uuid": "1e66e976d34d4e28f5a92241b0ea82a2a66363ea"
   },
   "source": [
    "#### shared_articles.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f09d2247-a40c-4aaf-90ce-15a8721a3036",
    "_uuid": "e64f4fa8a4751274bd2d37a0f45d2d3d664d6c3e"
   },
   "source": [
    "Так как в файле перечислены даже удалённые статьи, то мы их сразу удалим (на самом деле они могли бы быть нам полезны для подсчёта различных величин, хоть мы и не можем их рекомендовать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e601f966-d03f-4edc-886f-ca3d511a8045",
    "_uuid": "569c301bd128f66f29b4d97c34171e4d1712015a"
   },
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv('data/shared_articles.csv')\n",
    "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
    "articles_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "487936d5-d7b3-487d-9ef1-e3ba1e4bc421",
    "_uuid": "3f96f2d88fa86814e2fa1273d80f26d2559823fd"
   },
   "source": [
    "#### users_interactions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "325b8db8-ef44-4b59-8138-2a59bd02d66e",
    "_uuid": "86694f1b80b04b8f9b961148fb265f355f202b26"
   },
   "source": [
    "В колонке eventType описаны действия, которые могли совершать пользователи над статьёй:  \n",
    "- VIEW\n",
    "- LIKE\n",
    "- COMMENT CREATED\n",
    "- FOLLOW\n",
    "- BOOKMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "445d39ec-f6b0-4155-9f92-0a2540918bd1",
    "_uuid": "9829842326037e364de457f832deceae074d6164"
   },
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv('data/users_interactions.csv')\n",
    "interactions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.personId = interactions_df.personId.astype(str)\n",
    "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "articles_df.contentId = articles_df.contentId.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "585f81a5-c6ff-4399-bbec-901c41fc7285",
    "_uuid": "6abb0af8474eabb50be7a9e6496bfa75ec1b2bd9"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bad1a6c9-0258-4b89-85f9-bec89a523662",
    "_uuid": "84c2e91561d5de6afa7c45c173022193664c770e"
   },
   "source": [
    "В логах встречаются различные действия пользователей. Однако мы хотим работать лишь с одной величиной, характеризующей всё взаимодействие пользователя со статьёй. Предлагается задать действиям следующие веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3239c376-05b8-4a58-9afc-f6f57f67405f",
    "_uuid": "b06f8c0b082f0ad07bf773a5ad2fae33c1f7acc2"
   },
   "outputs": [],
   "source": [
    "event_type_strength = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте числовую величину \"оценки\" пользователем статьи с указанными выше весами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df['eventStrength'] = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c92aa80-2926-44db-b358-c4c32de806c4",
    "_uuid": "91100a395fdf4fb20df02c8d248072457c980b5d"
   },
   "source": [
    "Ремендательные системы подвержены проблеме холодного старта. В рамках данного задания предлагается работать только с теми пользователями, которые взаимодействовали хотя бы с 5 материалом.\n",
    "\n",
    "Оставьте только таких пользователей. Их должно остаться 1140."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bad1d8ea-9b67-4a47-80c5-87a5e55c4f38",
    "_uuid": "1698c88340183baa7f3ebb8c3b60eaa8e6ca708f"
   },
   "outputs": [],
   "source": [
    "users_interactions_count_df = (\n",
    "    interactions_df\n",
    "    .groupby(['personId', 'contentId'])\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby('personId').size())\n",
    "print('# users:', len(users_interactions_count_df))\n",
    "\n",
    "users_with_enough_interactions_df = \\\n",
    "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "print('# users with at least 5 interactions:',len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставьте только те взаимодействия, которые касаются только отфильтрованных пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e79a418-a9d6-4e01-9f38-9b290a645626",
    "_uuid": "0f428a4c6e76f95de7ea328dc33c6539389ae5f0"
   },
   "outputs": [],
   "source": [
    "interactions_from_selected_users_df = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# interactions before:', interactions_df.shape)\n",
    "print('# interactions after:', interactions_from_selected_users_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной постановке каждый пользователей мог взаимодействовать с каждой статьёй более 1 раза (как минимум совершая различные действия). Предлагается \"схлопнуть\" все действия в одно взаимодействие с весом, равным сумме весов. \n",
    "\n",
    "Однако полученное число будет в том числе тем больше, чем больше действий произвёл человек. Чтобы уменьшить разброс предлагается взять логарифм от полученного числа (можно придумыват другие веса действиям и по-другому обрабатывать значения).\n",
    "\n",
    "Также сохраним последнее значение времени взаимодействия для разделениея выборки на обучение и контроль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54c82dd1-1102-4f11-ac6a-7993f8e5e842",
    "_uuid": "dcd64b20b47cf2c365341303ff410626a801f7a6"
   },
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId']).eventStrength.sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index().set_index(['personId', 'contentId'])\n",
    ")\n",
    "interactions_full_df['last_timestamp'] = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId'])['timestamp'].last()\n",
    ")\n",
    "        \n",
    "interactions_full_df = interactions_full_df.reset_index()\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьём выборку на обучение и контроль по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e594a5ef-255a-4d30-9ab2-7cebe12fe798",
    "_uuid": "babda61be5306281b34422dbded67675a0aab17d"
   },
   "outputs": [],
   "source": [
    "split_ts = 1475519530\n",
    "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
    "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства подсчёта качества запишем данные в формате, где строка соответствует пользователю, а столбцы будут истинными метками и предсказанями в виде списков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = (\n",
    "    interactions_train_df\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={'contentId': 'true_train'})\n",
    "    .set_index('personId')\n",
    ")\n",
    "\n",
    "interactions['true_test'] = (\n",
    "    interactions_test_df\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    ")\n",
    "\n",
    "# заполнение пропусков пустыми списками\n",
    "interactions.loc[pd.isnull(interactions.true_test), 'true_test'] = [\n",
    "    list() for x in range(len(interactions.loc[pd.isnull(interactions.true_test), 'true_test']))]\n",
    "\n",
    "interactions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2fac2a15-cc5c-4f31-8818-8065b0d2dc16",
    "_uuid": "59dd2131949c4d7e801114bffc11fb439c930b4c"
   },
   "source": [
    "## Часть 1: Baseline (модель по популярности)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самой простой моделью рекомендаций (при этом достаточно сильной!) является модель, которая рекомендует наиболее популярные предметы. \n",
    "\n",
    "Предлагается реализовать её. Давайте считать, что рекомендуем мы по 10 материалов (такое ограничение на размер блока на сайте).\n",
    "\n",
    "Посчитайте популярность каждой статьи, как сумму всех \"оценок\" взаимодействий с ней. Отсортируйте материалы по их популярности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_content = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо сделать предсказания для каждого пользователя. Не забывайте, что надо рекомендовать то, что пользователь ещё не читал (для этого нужно проверить, что материал не встречался в true_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "\n",
    "interactions['prediction_popular'] = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настало время оценить качество. Посчитайте precision@10 для каждого пользователя (доля угаданных рекомендаций). Усредните по всем пользователям. Везде далее будем считать эту же метрику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Коллаборативная фильтрация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к более сложному механизму рекомендаций, а именно коллаборативной фильтрации. Суть коллаборативной фильтрации в том, что учитывается схожесть пользователей и товаров между собой, а не факторы, которые их описывают. \n",
    "\n",
    "__Предлагается на выбор реализовать один из двух подходов__: memory-based или модель со скрытыми переменные.\n",
    "\n",
    "Для начала для удобства составим матрицу \"оценок\" пользователей. Нули будут обозначать отсутствие взаимодействия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.pivot_table(\n",
    "    interactions_train_df,\n",
    "    values='eventStrength',\n",
    "    index='personId',\n",
    "    columns='contentId').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте схожести пользователей с помощью корреляции Пирсона. Для каждой пары учитываем только ненулевые значения.\n",
    "\n",
    "Для скорости работы лучше переходить от pandas к numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_m = ratings.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_users = np.zeros((len(ratings_m), len(ratings_m)))\n",
    "\n",
    "for i in tqdm_notebook(range(len(ratings_m)-1)):\n",
    "    for j in range(i+1, len(ratings_m)):\n",
    "        \n",
    "        # nonzero elements of two users\n",
    "        mask_uv = (ratings_m[i] != 0) & (ratings_m[j] != 0)\n",
    "        \n",
    "        # continue if no intersection\n",
    "        if np.sum(mask_uv) == 0:\n",
    "            continue\n",
    "            \n",
    "        # get nonzero elements\n",
    "        ratings_v = ratings_m[i, mask_uv]\n",
    "        ratings_u = ratings_m[j, mask_uv]\n",
    "        \n",
    "        # normalization\n",
    "        # ...\n",
    "        \n",
    "        # for nonzero std\n",
    "        if len(np.unique(ratings_v)) < 2 or len(np.unique(ratings_u)) < 2:\n",
    "            continue\n",
    "        \n",
    "        similarity_users[i,j] = # your code\n",
    "        similarity_users[j,i] = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть матрицы схожести пользователей. Их можно использовать для рекомендаций.\n",
    "\n",
    "Для каждого пользователя:\n",
    "\n",
    "1. Найдём пользователей с похожестью больше $\\alpha$ на нашего пользователя.\n",
    "2. Посчитаем для каждой статьи долю пользователей (среди выделенных на первом шаге), которые взаимодействовали со статьёй.\n",
    "3. Порекомендуем статьи с наибольшими долями со второго шага (среди тех, которые пользователь ещё не видел).\n",
    "\n",
    "В нашем примере данных не очень много, поэтому возьмём $\\alpha = 0$.\n",
    "\n",
    "После того, как будут сделаны предсказания (новый столбец в interactions), посчитайте качество по той же метрике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n",
    "interactions['prediction_user_based'] = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель со скрытыми переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем подход с разложением матрицы оценок. Для этого сделайте сингулярное разложение (svd в scipy.linalg), на выходе вы получите три матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения у матрицы с сингулярными числами отсортированы по убыванию. Допустим мы хотим оставить только первые 100 компонент (и получить скрытые представления размерности 100). Для этого необходимо оставить 100 столбцов в матрице U, оставить из sigma только первые 100 значений (и сделать из них диагональную матрицу) и 100 столбцов в матрице V. Перемножьте преобразованные матрицы ($\\hat{U}, \\hat{sigma}, \\hat{V^T}$), чтобы получить восстановленную матрицу оценок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте качество аппроксимации матрицы по норме Фробениуса (среднеквадратичную ошибку между всеми элементами соответствующими элементами двух матриц). Сравните его с простым бейзлайном с константным значением, равным среднему значению исходной матрицы. У аппроксимации ошибка должна получиться ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно делать предсказания по матрице. Сделайте их (не забывайте про то, что уже было просмотрено пользователем), оцените качество. Для этого необходимо для каждого пользователя найти предметы с наибольшими оценками в восстановленной матрице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этих пор мы не проводили никаких преобразований с матрицей оценок. Отцентрируйте все ненулевые (!) значения по каждому пользователю. Сделайте предсказания, посчитайте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Факторизационные машины (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем факторизационные машины из библиотеки pyFM (так как можно работать прямо из питона). https://github.com/coreylynch/pyFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к обобщению матричных разложений — факторизационным машинам, которые работают могут работать с контентной информацией. Вспомним, какие данные у нас изначально были:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В факторизационную машину можно загрузить \"айдишники\" пользователей и статей (то есть сделать аналог коллаборативной фильтрации) и одновременно различные признаки.\n",
    "\n",
    "Удобно обрабатывать категориальные переменные (id и другие) можно с помощью DictVectorizer. Например, процесс может выглядить вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = [\n",
    "#     {\"user\": \"1\", \"item\": \"5\", \"age\": 19},\n",
    "#     {\"user\": \"2\", \"item\": \"43\", \"age\": 33},\n",
    "#     {\"user\": \"3\", \"item\": \"20\", \"age\": 55},\n",
    "#     {\"user\": \"4\", \"item\": \"10\", \"age\": 20},\n",
    "# ]\n",
    "# v = DictVectorizer()\n",
    "# X = v.fit_transform(train)\n",
    "# y = np.repeat(1.0, X.shape[0])\n",
    "# fm = pylibfm.FM()\n",
    "# fm.fit(X,y)\n",
    "# fm.predict(v.transform({\"user\": \"1\", \"item\": \"10\", \"age\": 24}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируйте таблицу с признаками в таком виде, где будут id пользователя, статьи и автора статьи и несколько признаков, которые вы сможете придумать. В качестве целевой переменной возьмите \"силу\" взаимодействия пользователя с каждой статьёй (помним, что у нас там все примеры по сути положительные). Запустите обучение модели на несколько итераций и сделайте предсказания. Какое качество удаётся достич? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(interactions_train_df))):\n",
    "    features = {}\n",
    "    features['personId'] = str(interactions_test_df.iloc[i].personId)\n",
    "    features['contentId'] = str(interactions_test_df.iloc[i].contentId)\n",
    "    \n",
    "    # ... \n",
    "    \n",
    "    train_data.append(features)\n",
    "    \n",
    "# and test set too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем, получим разреженные матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "\n",
    "train_features = dv.fit_transform(train_data)\n",
    "test_features = dv.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = pylibfm.FM(num_factors=10, num_iter=30, task='regression')\n",
    "fm.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте добавить случайные негативные примеры из статей, с которыми пользователь не взаимодействовал. Какое качество удалось достичь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Контентные  модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части реализуем альтернативных подход к рекомендательным системам — контентные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы будем оперировать не матрицей с оценками, а классической для машинного обучения матрицей объекты-признаки. Каждый объект будет характеризовать пару user-item и содержать признаки, описывающие как пользователя, так и товар. Кроме этого признаки могут описывать и саму пару целиком.\n",
    "\n",
    "Матрица со всеми взаимодействиями уже получена нами на этапа разбиения выборки на 2 части. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придумаем и добавим признаков о пользователях и статьях. Сначала добавим информацию о статьях в данные о взаимодействиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_df = interactions_train_df.merge(articles_df, how='left', on='contentId')\n",
    "interactions_test_df = interactions_test_df.merge(articles_df, how='left', on='contentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first feature index\n",
    "features_start = len(interactions_train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения модели нам придётся делать предсказания на тестовой выборке для всех возможных пар статья-пользователь. Подготовим такую матрицу, чтобы параллельно посчитать признаки для неё."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_personId = np.repeat(interactions.index, len(articles_df)) \n",
    "test_contentId = list(articles_df.contentId) * len(interactions)\n",
    "\n",
    "test = pd.DataFrame(\n",
    "    np.array([test_personId, test_contentId]).T,\n",
    "    columns=['personId', 'contentId'])\n",
    "test = test.merge(articles_df, how='left', on='contentId')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте признаки-индикаторы возможных значений contentType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.contentType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_df['is_HTML'] = interactions_train_df.contentType == 'HTML'\n",
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте признаки \"длина названия\" и \"длина текста\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте признаки-индикаторы языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на полученных признаках градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm \n",
    "\n",
    "regressor = lightgbm.LGBMRegressor()\n",
    "regressor.fit(interactions_train_df[interactions_train_df.columns[features_start:]],\n",
    "              interactions_train_df.eventStrength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте предсказания на тестовой выборке, сформируйте из них рекомендации. Оцените их качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категориальные переменные с большим количеством значений можно закодировать с помощью mean-target кодирования. Закодируйте так id статьи и пользователя. Обучите новую модель и оцените качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим негативных примеров в выборку — для каждого пользователя выберем случайные статьи, которые он не читал и отметим их нулём. Попробуйте добавить негативных примеров в обучающую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
